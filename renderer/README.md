# Renderer

## Getting started
### Installing the renderer
Once you have cloned this repo, go to the root of the repo (not the [renderer/](.) folder) and run:
```bash
git submodule update --init --recursive
```

Then come back to the [renderer/](.) folder and create a build directory, to build an executable:
```bash
mkdir build && cd build
cmake ..
make
```
During cmake you might get errors. This is due to not having all required dependencies installed. Normally cmake tells you what packages you are missing. Install them per your operating system, and you should be good to go.
If the build succeeds you should have the `RTDLF` executable file, which you can use to run the renderer.

### Running the renderer
You should have a folder containing the generated data by the preprocessor. If not please see [the preprocessor's README.md](../preprocessor/README.md).

This folder should contain everything needed to render the scene, and thus you can pass the folder to the renderer

```bash
./RTDLF <path-preprocessor-out>
```

## Controls

- `h`: move viewpoint left
- `l`: move viewpoint right
- `j`: move viewpoint down
- `k`: move viewpoint up 

- `i`: zoom in
- `o`: zoom out

- `left arrow`: rotate camera left
- `right arrow`: rotate camera right
- `down arrow`: rotate camera down 
- `up arrow`: rotate camera up

- `s`: pause playback
- `g`: resume playback

> Note that no new cameras get loaded on pause. Inpainted regions will thus stay the same untill you resume playback.

- `Esc`: Kill the program

## All cli options

| Argument    | Description                                       |
| ----------- | ------------------------------------------------- |
| `input-dir` | The input directory containing the necessary data |


| Optional Argument          | Description                                                                                                      |
| -------------------------- | ---------------------------------------------------------------------------------------------------------------- |
| `--help`                   | Show the help message                                                                                            |
| `-m mesh-type`             | Specifies the mesh type (**default:** `vmesh`)                                                                   |
| `-f fragment-type`         | Specifies the fragment type (**default:** `yuv`)                                                                 |
| `-w width`                 | Specifies the output width (**default:** `1280`)                                                                 |
| `-h height`                | Specifies the output height (**default:** `720`)                                                                 |
| `-c cameras`               | Specifies the number of cameras to use (**default:** `3`)                                                        |
| `--headless frame outPath` | Render a single frame to the specified output path as a PNG image. Example: `--headless 15 ./output/frame15.png` |

The application will start from the viewpoint of the first camera. Should you want to change the viewpoint (e.g. for headless rendering) you can do this by changing the `view` matrix in the `metadata.json` file that is generated by the preprocessor.

Depending on the chosen mesh-type and fragment-type, you will need to have the preprocessor generate other data.
Note that most options are just availble from tryouts during development. Only `vmesh` and `yuv` are recommended for a good experience.

Fun options to play around with:
```bash
-v voxel # render the voxel aligned point cloud as voxel geometry
-f dummy # will render depth on top of the geometry
-f ambient # will render only inpainting data on top of the geometry
```

